# analyze_logs.py
import json
from collections import Counter
from datetime import datetime

LOG_FILE = "conversation_log.json"

# ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
positive_keywords = ["‡∏î‡∏µ", "‡∏ä‡∏≠‡∏ö", "‡∏™‡∏ô‡∏∏‡∏Å", "‡∏û‡∏≠‡πÉ‡∏à", "‡∏°‡∏µ‡∏û‡∏•‡∏±‡∏á", "‡∏ï‡∏∑‡πà‡∏ô‡πÄ‡∏ï‡πâ‡∏ô", "‡∏™‡∏á‡∏ö", "‡∏£‡∏±‡∏Å"]
negative_keywords = ["‡πÄ‡∏Ñ‡∏£‡∏µ‡∏¢‡∏î", "‡πÄ‡∏´‡∏ô‡∏∑‡πà‡∏≠‡∏¢", "‡∏Å‡∏î‡∏î‡∏±‡∏ô", "‡πÄ‡∏ö‡∏∑‡πà‡∏≠", "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÅ‡∏£‡∏á", "‡πÇ‡∏Å‡∏£‡∏ò", "‡πÄ‡∏®‡∏£‡πâ‡∏≤", "‡∏™‡∏±‡∏ö‡∏™‡∏ô"]

def load_all_conversations():
    if not LOG_FILE.endswith(".json"):
        raise ValueError("LOG_FILE ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå .json ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå")

    try:
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ùå ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
        return []

def analyze_behavior(sessions):
    all_entries = []
    word_counter = Counter()
    pos_count = neg_count = neutral_count = total_words = 0
    longest_answer = ""

    for session in sessions:
        conv = session.get("conversation", [])
        for entry in conv:
            answer = entry["user_answer"]
            words = answer.split()
            word_counter.update(words)
            total_words += len(words)

            lowered = answer.lower()
            if any(word in lowered for word in positive_keywords):
                pos_count += 1
            elif any(word in lowered for word in negative_keywords):
                neg_count += 1
            else:
                neutral_count += 1

            if len(answer) > len(longest_answer):
                longest_answer = answer

            all_entries.append(entry)

    total = len(all_entries)
    avg_length = total_words / total if total else 0
    common_words = word_counter.most_common(10)

    print(f"\nüìä ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(sessions)} session ({total} ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö):\n")
    print(f"- ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: {avg_length:.2f} ‡∏Ñ‡∏≥")
    print(f"- ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {[w for w, _ in common_words]}")
    print(f"- ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:")
    print(f"    ‚Ä¢ ‡πÄ‡∏ä‡∏¥‡∏á‡∏ö‡∏ß‡∏Å: {pos_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    print(f"    ‚Ä¢ ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏ö: {neg_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    print(f"    ‚Ä¢ ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á: {neutral_count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    print(f"- ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î:\n  \"{longest_answer}\"")

    print("\nüß† ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ session:")
    for i, session in enumerate(sessions, 1):
        print(f"\nüìå Session {i}:")
        print(f"üìÖ ‡πÄ‡∏ß‡∏•‡∏≤: {session['conversation'][0]['timestamp']}")
        print("üìù Summary (TH):", session.get("summary", "[‡πÑ‡∏°‡πà‡∏°‡∏µ]"))
        print("üåê Summary (EN):", session.get("summary_en", "[‡πÑ‡∏°‡πà‡∏°‡∏µ]"))

if __name__ == "__main__":
    print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå conversation logs...")
    all_sessions = load_all_conversations()
    analyze_behavior(all_sessions)
