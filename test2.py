import json
import os
import re
from datetime import datetime
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate

MODEL_NAME = "llama3"

def load_prompts(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    sections = {}
    current_key = None
    buffer = []

    for line in content.splitlines():
        if line.startswith("===") and line.endswith("==="):
            if current_key and buffer:
                sections[current_key] = "\n".join(buffer).strip()
            current_key = line.strip("=").strip()
            buffer = []
        else:
            buffer.append(line)
    if current_key and buffer:
        sections[current_key] = "\n".join(buffer).strip()

    return sections

# ‡πÇ‡∏´‡∏•‡∏î prompt ‡∏à‡∏≤‡∏Å system_prompt.txt
prompts = load_prompts("system_prompt.txt")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Model ‡πÅ‡∏•‡∏∞ Prompt Chain
model = OllamaLLM(model=MODEL_NAME, system=prompts["system"])

question_prompt_th = ChatPromptTemplate.from_template(prompts["question_th"])
summary_prompt_th = ChatPromptTemplate.from_template(prompts["summary_th"])
next_question_prompt_th = ChatPromptTemplate.from_template(prompts["next_question_th"])
question_prompt_en = ChatPromptTemplate.from_template(prompts["question_en"])
summary_prompt_en = ChatPromptTemplate.from_template(prompts["summary_en"])
next_question_prompt_en = ChatPromptTemplate.from_template(prompts["next_question_en"])

question_chain_th = question_prompt_th | model
summary_chain_th = summary_prompt_th | model
next_question_chain_th = next_question_prompt_th | model
question_chain_en = question_prompt_en | model
summary_chain_en = summary_prompt_en | model
next_question_chain_en = next_question_prompt_en | model

conversation_log = {
    "conversation": [],
    "summary": "",
    "summary_en": "",
    "season_scores": "",
    "top_season": ""
}

def handle_conversation(num_questions=5):
    context = ""

    print("üí¨ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà! ‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î\n")

    for i in range(num_questions):
        timestamp = datetime.now().isoformat()

        if i == 0:
            model_question = "Q1 (TH): ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£?\nQ1 (EN): How would you describe yourself in one sentence?"
            model_prompt_th = "‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô"
            model_prompt_en = "Initial question without history"
        elif i >= 3:
            model_question_th = next_question_chain_th.invoke({"context": context}).strip()
            model_question_en = next_question_chain_en.invoke({"context": context}).strip()
            model_question = f"Q{i+1} (TH): {model_question_th}\nQ{i+1} (EN): {model_question_en}"
        else:
            model_question_th = question_chain_th.invoke({"context": context}).strip()
            model_question_en = question_chain_en.invoke({"context": context}).strip()
            model_question = f"Q{i+1} (TH): {model_question_th}\nQ{i+1} (EN): {model_question_en}"

        print(f"\n{model_question}")
        user_answer = input("You: ").strip()

        if user_answer.lower() == "exit":
            print("üëã ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡πâ‡∏ß")
            break

        context += f"\n‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {user_answer}"

        conversation_log["conversation"].append({
            "timestamp": timestamp,
            "model_prompt": model_prompt_th,
            "model_prompt_en": model_prompt_en,
            "model_question": model_question,
            "user_answer": user_answer
        })

    print("\nüß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ...\n")

    summary_th = summary_chain_th.invoke({"context": context}).strip()
    summary_en = summary_chain_en.invoke({"context": context}).strip()

    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏§‡∏î‡∏π
    score_prompt = prompts["season_scores"].replace("{context}", context)
    season_scores_text = model.invoke(score_prompt).strip()

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏õ‡πá‡∏ô dict
    season_scores = {}
    for line in season_scores_text.splitlines():
        match = re.match(r"(‡∏§‡∏î‡∏π.+?):\s*([0-9]+)", line)
        if match:
            season = match.group(1).strip()
            score = int(match.group(2))
            season_scores[season] = score

    # ‡∏´‡∏≤‡∏§‡∏î‡∏π‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    top_season = max(season_scores.items(), key=lambda x: x[1])[0]
    summary_th += f"\n\nüå§Ô∏è ‡∏§‡∏î‡∏π‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: **{top_season}**"

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï log
    conversation_log["summary"] = summary_th
    conversation_log["summary_en"] = summary_en
    conversation_log["season_scores"] = season_scores
    conversation_log["top_season"] = top_season

    print("üß† ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏†‡∏≤‡∏û (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢):\n")
    print(summary_th)
    print("\nüß† Personality Summary (English):\n")
    print(summary_en)
    print("\nüå∏ ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏§‡∏î‡∏π:\n")
    for s, score in season_scores.items():
        print(f"- {s}: {score}")
    print(f"\nüéØ ‡∏§‡∏î‡∏π‡πÄ‡∏î‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {top_season}")

    save_conversation_to_json()

def save_conversation_to_json(filename="conversation_log.json"):
    if os.path.exists(filename):
        with open(filename, "r", encoding="utf-8") as f:
            try:
                existing_data = json.load(f)
                if isinstance(existing_data, dict):
                    all_logs = [existing_data]
                elif isinstance(existing_data, list):
                    all_logs = existing_data
                else:
                    all_logs = []
            except json.JSONDecodeError:
                print("‚ö†Ô∏è ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á/‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà...")
                all_logs = []
    else:
        all_logs = []

    all_logs.append(conversation_log)

    with open(filename, "w", encoding="utf-8") as f:
        json.dump(all_logs, f, ensure_ascii=False, indent=2)

    print(f"\nüìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {filename}")


if __name__ == "__main__":
    handle_conversation()
